# 評価（by gpt-5）

**総合スコア**: 90/100

## 良い点
- **実運用を意識したパイプライン**: 設定ファイル・CI定義の読み取り、`phpcs/php-cs-fixer` の dry-run 差分解析、`composer.json` 解析など、確定情報の取得が明確。
- **高度なパターン抽出**: ASTのベクトル化＋クラスタリング（k-means/HDBSCAN）でコンポーネント別の代表スニペットを抽出する発想が強い。LLM要約と合わせて「説明可能なスタイル」に落とし込める。
- **評価設計が多層**: ハードルール（規約違反）、ソフトメトリクス（phpmetrics等）、LLM評価のハイブリッドで、採点の頑健性が高い。Elo/Glickoでスキル推移管理の提案も◎。
- **スタイルプロファイルの再利用性**: YAML/JSONへの正規化例が具体的で、出題・採点・フィードバックに横断利用できる構成。
- **OSS候補の選定軸が妥当**: ベストプラクティス/ドメイン特化/静的解析先進など、検証観点の幅がある。

## 改善余地
- **実装具体度の偏り**: インフラ（pgvector/DuckDBなど）やクラスタリングは強力だが、PoC段階では過剰。まずは簡易統計＋ASTパターン＋dry-run差分で十分に検証可能。
- **FW文脈の既定バンドル化**: Laravel/Symfony/WordPressごとの「既定ルールセット」提示があると初動が速い（例: Controller/Request/Policyの“必須/推奨”）。
- **LLM評価の安定化**: LLMスコアに対するガード（ルーブリック固定、chain-of-thought非依存、少数例参照）等の運用ガイドがあると再現性が上がる。

## 総評
設定→AST/統計→クラスタ→LLM要約→ルール化→採点・レベル化の一本線が通っており、実験から本番運用まで拡張しやすい。PoCでは軽量化しつつ、順次クラスタリング/LLM評価を足す進め方が最適。


